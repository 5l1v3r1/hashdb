% To build, please type: pdflatex draft1.tex

\documentclass[12pt,twoside]{article}
\usepackage[bf,small]{caption}
\usepackage[letterpaper,hmargin=1in,vmargin=1in]{geometry}
\usepackage{paralist} % comapctitem, compactdesc, compactenum
\usepackage{titlesec}
\usepackage{titletoc}
\usepackage{times}
\usepackage{hyperref}
\usepackage{algorithmic}
\usepackage{graphicx}
\graphicspath{{./graphics/}}
\usepackage{xspace}
\usepackage{verbatim}
\usepackage{url}
\usepackage{float}
\hyphenation{Sub-Bytes Shift-Rows Mix-Col-umns Add-Round-Key}

\setlength{\parskip}{12pt}
\setlength{\parindent}{0pt}

\newcommand{\hdb}{\emph{hashdb}\xspace}
\newcommand{\libhdb}{\emph{libhashdb}\xspace}
\newcommand{\bulk}{\emph{bulk\_extractor}\xspace}
\newcommand{\hashid}{\emph{hashid}\xspace}
\newcommand{\hid}{\emph{hashid}\xspace}
\newcommand{\mdd}{\emph{md5deep}\xspace}
\newcommand{\bev}{\emph{Bulk Extractor Viewer}\xspace}
\newcommand{\fiwalk}{\emph{fiwalk}\xspace}

\begin{document}
Draft review 2.

\subsubsection*{1.1 sentence 1}
Not "hash blocks".  Hashes are calculated from blocks of data,
for example 4096-byte blocks of data.

Tasks such as malware detection
and child exploitation detection.

Par. 3: plese identify unit as bytes: "(usually 4096 bytes)"

Great intro, thanks.


\subsubsection*{2}
Par. 2: "media files and disk images": I'm not clear, What is a media file?
A disk image as a file vs. a mounted image?

par. 2: With the \hdb library,
the process of creating and populating a new database is indivisible.
Please make sure it doesn't imply that they are separable.

par. 2 and Fig. 1:
The \bulk \hid scanner populates file \texttt{identified\_blocks.txt}
with features.  These features are block hash values that match.
I'm a bit uncomfortable with "matching hash features".
Possibly "matching hash values"?

\subsubsection*{3.1.2}
Please change version 1.4.1 to 1.4.5.
\bulk v1.4.1 is a temporary provision for Beta demos.

\subsubsection*{3.3.2}
Typo: \textit{mock\_video\_vb}

Regarding:
\begin{verbatim}
$ls
total 176
\end{verbatim}
Windows users will type \texttt{dir}.
I don't understand \texttt{total 176}.

Par. 7: not "offset of the Forensic Path", it is the Forensic Path.
The forensic path identifies the location of the feature.

Par. 7: Please remove last sentence
that the forensic path is the first field of all feature files
\bulk generates.
This fact about \bulk is distracting here.

Last par.:
We are not changing the \hdb tool design to reduce false positives.
\hdb provides commands \texttt{subtract} and \texttt{deduplicate}
which allow the user to remove hashes generated from low entropy data
or to remove popular hashes, respectively.
Users will use these commands to manage false positives.
In time, users and researchers will better understand the nature and frequency
of block hash false positives.
In any event, my solution is to use \texttt{subtract} to generate a whitelist,
or use \texttt{deduplicate}
with the assumption that all duplicates have low entropy.
\texttt{deduplicate} runs the risk that valid blacklist data will get entered
twice and thus be removed.
So I really recommend \texttt{subtract}.

We thought about designing a built-in ability
to detect and drop low-entropy data,
but I don't think that will happen.
The low-entropy dataset is not well defined,
and imposing a filter at such a low level seems not clean.
Subtracting whitelist hashes is a well defined function and its usage is clean.

\subsubsection*{4.2}
Table 1:
Sorry, I see I haven't fixed usage yet.
Scan is \texttt{scan path\_or\_socket},
not \texttt{scan hashdb},

Socket is only used in these places:
\begin{compactitem}
\item The \texttt{socket} command provides a socket
through which scans may be performed.
\item The \hdb \texttt{scan} command.
\item The \bulk \hid scanner, in scan mode.
\end{compactitem}

Table 4 is missing command \texttt{expand\_identified\_blocks},
which prints out the three source informations
that you incorrectly attribute to the \texttt{get\_sources} command.
The \texttt{expand\_identified\_blocks} command
takes the found hash features in file \texttt{identified\_blocks.txt}
and returns these three source values for each hash feature listed.
If one of the hash values is sourced from 20 places, then 20 source attributions
will be listed for it.

The \texttt{get\_sources} command gives a top-level view
of the repository names and filenames in the database.
It does not print out hash values.
It just prints out the (repository name, filename) pairs
that have ever been added to the database,
even if all the hash values that got them there in the first place
have been deleted.
The user uses this command to see what repositories and files
have gone into the database.
Users will like this command after they use the \texttt{intersect} command
because it immediately reveals the files involved,
with the thickness of all the hash value information stripped away.

\subsubsection*{4.3.1}
Can bullet \texttt{hashdb\_mode} indicate the three possible assignment values
more clearly?
Perhaps indented bullets, one for each, or syntax \texttt{none|import|scan}
as is done for \texttt{hashdb\_hashdigest\_type}?  Thanks.

On the note about non-relevant feature file output: you might suggest that they
disable all but the \hid scanner via the \bulk \texttt{-E hashid} option
because \bulk will run much faster with the other scanners turned off.

\subsubsection*{4.4}
Please make it clear that we recommend using btree unless performance
is slow when scanning.
When importing, unordered-hash is their worst choice.
Perhaps just say "slow when scanning.  If slow when scanning...".

Bloom: Please don't say "is or is or not" because Bloom doesn't know "is".
Bloom just knows "maybe is" and "is not".
We exploit this fact to optimize performance.
When there are too many entries in the Bloom filter,
the Bloom filter becomes saturated and says "maybe is" too much,
so much so that the optimization benefit gets lost.
We then recommend using a larger Bloom filter.

Bloom: Please don't say "for advanced users" for Bloom filter 1.
Please recommend that if they want to improve scan speed,
tune Bloom 1 based on their database size
using the \texttt{--bloom1\_n <n>} option.

Users may want to keep bloom 2 off while advanced users may want to use bloom 2
for the reasons you describe next.

\subsubsection*{6}
Can this example be completed using the single-thread option yet?
I still see "REPLACE WITH OUTPUT WHEN IT RUNS PROPERLY".

The conclusion to the example is that there are 32 common hashes.
This is quite unsatisfying because we don't know the usefulness of this fact
by itself.
The hashes may be from system files or low entropy data,
or they may be significant but we don't know what data they correspond to.

Here are some ways to gain knowledge from the common hashes identified:
\begin{compactitem}
\item Constrain the matches further by using the \texttt{intersect} command
to intersect the database with a blacklist database,
and then use the \texttt{get\_sources} command
to find the blacklist filenames that these hash values correspond to.
\item Use \bev to navigate to the data that these hashes were generated from
to see if the raw data there is significant.
\item If the scanned image contains a file system,
try to use the \fiwalk tool to carve the files from which the hash values
were calculated.
\end{compactitem}

\end{document}

