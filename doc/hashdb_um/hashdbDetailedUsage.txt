Examples:
This example uses the md5deep tool to generate cryptographic hashes from
hash blocks in a file, and is suitable for importing into a hash database
using the hashdb "import" command.  Specifically:
"-p 4096" sets the hash block partition size to 4096 bytes.
"-d" instructs the md5deep tool to produce output in DFXML format.
"my_file" specifies the file that cryptographic hashes will be
generated for.
The output of md5deep is directed to file "my_dfxml_file.xml".
    md5deep -p 4096 -d my_file > my_dfxml_file.xml

This example uses the md5deep tool to generate hashes recursively under
subdirectories, and is suitable for importing into a hash database using
the hashdb "import" command.  Specifically:
"-p 4096" sets the hash block partition size to 4096 bytes.
"-d" instructs the md5deep tool to produce output in DFXML format.
"-r mydir" specifies that hashes will be generated recursively under
directory mydir.
The output of md5deep is directed to file "my_dfxml_file.xml".
    md5deep -p 4096 -d -r my_dir > my_dfxml_file.xml

This example creates a new hash database named my_hashdb.hdb with default
settings:
    hashdb create my_hashdb.hdb

This example imports hashes into hash database my_hashdb.hdb from DFXML input
file my_dfxml_file.xml, categorizing the hashes as sourced from repository
"my repository":
    hashdb import -r "my repository" my_hashdb.hdb my_dfxml_file.xml

This example exports hashes in my_hashdb.hdb to output DFXML file my_dfxml.xml:
    hashdb export my_hashdb my_dfxml.xml

This example adds hashes from hash database my_hashdb1.hdb to hash database
my_hashdb2.hdb:
    hashdb add my_hashdb1.hdb my_hashdb2.hdb

This example performs a database merge by adding my_hashdb1.hdb and my_hashdb2.hdb
into new hash database my_hashdb3.hdb:
    hashdb create my_hashdb3.hdb
    hashdb add_multiple my_hashdb1.hdb my_hashdb2.hdb my_hashdb3.hdb

This example removes hashes in my_hashdb1.hdb from my_hashdb2.hdb:
    hashdb subtract my_hashdb1.hdb my_hashdb2.hdb

This example creates a database without duplicates by copying all hashes
that appear only once in my_hashdb1.hdb into new database my_hashdb2.hdb:
    hashdb create my_hashdb2.hdb
    hashdb deduplicate my_hashdb1.hdb my_hashdb2.hdb

This example rebuilds the Bloom filters for hash database my_hashdb.hdb to
optimize it to work well with 50,000,000 different hash values:
    hashdb rebuild_bloom --bloom_n 50000000 my_hashdb.hdb

This example searches my_hashdb.hdb for hashes that match those in DFXML file
my_dfxml.xml and directs output to stdout:
    hashdb scan my_hashdb.hdb my_dfxml.xml

This example searches my_hashdb.hdb for hashes that match MD5 hash value
d2d95... and directs output to stdout:
    hashdb scan_hash my_hashdb.hdb d2d958b44c481cc41b0121b3b4afae85

This example prints out source metadata of where all hashes in my_hashdb.hdb
came from:
    hashdb sources my_hashdb.hdb

This example prints out size information about the hash database at file
path my_hashdb.hdb:
    hashdb size my_hashdb.hdb

This example prints out statistics about the hash database at file path
my_hashdb.hdb:
    hashdb statistics my_hashdb.hdb

This example prints out duplicate hashes in my_hashdb.hdb that have been
sourced 20 times:
    hashdb duplicates my_hashdb.hdb 20

This example prints out the table of hashes along with source information
for hashes associated with source index 1 in my_hashdb.hdb:
    hashdb hash_table my_hashdb.hdb 1

This example uses bulk_extractor to scan for hash values in media image
my_image that match hashes in hash database my_hashdb.hdb, creating output in
feature file my_scan/identified_blocks.txt:
    bulk_extractor -e hashdb -S hashdb_mode=scan
    -S hashdb_scan_path_or_socket=my_hashdb.hdb -o my_scan my_image

This example uses bulk_extractor to import hash values from media image
my_image into hash database my_scan/hashdb.hdb:
    bulk_extractor -e hashdb -S hashdb_mode=import -o my_scan my_image

This example creates new hash database my_hashdb.hdb using various tuning
parameters.  Specifically:
"-p 512" specifies that the hash database will contain hashes for data
hashed with a hash block size of 512 bytes.
"-m 2" specifies that when there are duplicate hashes, only the first
two hashes of a duplicate hash value will be copied.
"--bloom enabled" specifies that the Bloom filter is enabled.
"--bloom_n 50000000" specifies that the Bloom filter should be sized to expect
50,000,000 different hash values.
    hashdb create -p 512 -m 2 --bloom enabled --bloom_n 50000000
    my_hashdb.hdb

Using the md5deep tool to generate hash data:
hashdb imports hashes from DFXML files that contain cryptographic
hashes of hash blocks.  These files can be generated using the md5deep tool
or by exporting a hash database using the hashdb "export" command.
When using the md5deep tool to generate hash data, the "-p <partition size>"
option must be set to the desired hash block size.  This value must match
the hash block size that hashdb expects or else no hashes will be
copied in.  The md5deep tool also requires the "-d" option in order to
instruct md5deep to generate output in DFXML format.  Please see the md5deep
man page.

Using the bulk_extractor hashdb scanner:
The bulk_extractor hashdb scanner provides two capabilities: 1) scanning
a hash database for previously encountered hash values, and 2) importing
block hashes into a new hash database.  Options that control the hashdb
scanner are provided to bulk_extractor using "-S name=value" parameters
when bulk_extractor is invoked.  Please type "bulk_extractor -h" for
information on usage of the hashdb scanner.  Note that the hashdb scanner
is not available unless bulk_extractor has been compiled with hashdb support.

Please see the hashdb Users Manual for further information.
