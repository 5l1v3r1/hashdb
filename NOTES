Note: made changes to xbtree to remove compiler errors/warnings.
This will be replaced with a new version of boost btree in the future.

Note: removed use of iterator_facade because it causes many compiler warnings like this:
warning: base class ‘class boost::iterator_facade<burst_manager_map<md5_t, source_lookup_record_t>::manager_iterator, const std::pair<const md5_t, source_lookup_record_t>, boost::forward_traversal_tag, const std::pair<const md5_t, source_lookup_record_t>&, long int>’ has a non-virtual destructor [-Weffc++]
This change helped ensure efficient usage (prefix increment), reduces the call chain, and allows control over what the compiler generates, specifically, operator= and the copy constructor.

Note: 
Removed the dependency on libtoolize by porting libxml++ to libxml2.  libxml++ requires libtoolize because it requires PKG_CHECK_MODULES, requiring the use of AM_PROG_CC_C_O and requiring makefiles to define program_CPPFLAGS and program_LIBS.  Additional side effects are:

1)  the libtoolize comment libtoolize: `AC_PROG_RANLIB' is rendered obsolete by `LT_INIT'.
2)  all the generated .o files are prefixed with the primary name, which is annoying.
3)  Makefiles that need libxml++ require the lines:
          hashdb_CPPFLAGS = $(LIBXMLXX_CFLAGS) $(AM_CPPFLAGS)
          hashdb_LDFLAGS = $(LIBXMLXX_LIBS)
     which makes it so I can't readily compile with flag -lsystem for libxml++, which would make all those libxml++ warnings go away.

Here are some ramifications of this effort:
hashdb_settings_t now includes hashdigest_type.

When parsing DFXML, hashdigest_type and hash_block_size are passed to hashdb_manager.
This way, hashdb_manager can manage all checking and report all failures at the same place.

There were 3 similar DFXML parsers because the action is embedded in the parser:
  Add hash
  remove hash
  hashdb lookup

Now, the action is still embedded, but a consumer callback is used with a Template so there is only one DFXML scanner for all three.

Also, the XML settings parser has been ported to use libxml2, not libxml++.


xbtree modified for Windows port: include winsock2.h before windows.h
to avoid winsock2.h warning.

------------------------------------------------------------
Windows Port:
zmq for mingw is not static, so don't compile with --enable-static --disable-shared.

Later, may change zmq to static.  A code change recommendation is provided at
http://comments.gmane.org/gmane.network.zeromq.devel/17178

In configure.ac, changed boost to use macro boost.m4
because macros ax_boost_base.m4, ax_boost_system.m4, ax_boost_filesystem.m4
failed to work with mingw.  Specifically, ax_boost_system.m4 failed
with "Could not find a version of the library!".

------------------------------------------------------------
Issues with scan_hashid:

--------------------
(1)
These files moved from be13_api to dfxml/src:
    md5.c
    md5.h
    xml.c
    xml.h

The bulk_extractor git archive needs updated to include the dfxml package.
File bulk_extractor/src/Makefile needs to be changed so that these files
are found in dfxml/src instead of in be13_api.


--------------------
2)
I introduced HAVE_HASHID as the switch for generating the hashid scanner
and including the libhashdb library.  This impacts configure.ac
by adding libraries and the Boost library.  This implementation currently is
sloppy and I need to clean it up.

--------------------
3)
<resolved>.
--------------------
4)
<resolved>.

--------------------
5)
I changed usage of "#include <config.h>" to be in .c files and to never be 
in .h files.  I did this because it is inappropriate to have
"#include <config.h>" inside library header files.  In some cases, header
files require definitions that "#include <config.h>" would have provided,
such as WIN32.  The result is that the program including the library is
responsible for providing any definitions that the library needs.

--------------------
6)
When these issues get settled, I will want to push bulk_extractor changes
to github.  Currently I am archiving relavent files in SVN under sectorid2.


------------------------------------------------------------
Change in hashdb interface usage

Here is a kind of pseudocode view of current hashdb interfaces:

For hash lookup request, a vector of {hash id, hash digest} pairs is provided:
  hashes_request {
    vector<{id, digest}>
  }

For hash lookup response, a structure containing hash block size and a vector of {hash id, hash digest, duplicates count, lookup index, hash block offset value} is returned:
  hashes_response {
    hash_block_size;
    vector<{id, digest, count, lookup_index, hash_block_offset_value}>
  }

I like the request and response structures except for the use of variable "hash_block_size".  I provide "hash_block_size" so the user can validate that the hash block size the user expects and the hash block size the database uses match.  The test should be hidden, but the library doesn't know the hash block size the user is using.  I don't want to pass in hash_block_size during instantiation because the reason is obscure.  Also, testing on hash block size alone does not cover potential future checks.

I resolved this by removing the check.  The use must check the xml returned by "get_hashdb_info" interface to determine the hash_block_size.

------------------------------------------------------------
Testing:
Create hashdb of /corp/nps/files/govdocs1/.
Create hashdb of malware/.
Work under /raid/bdallen.
Perform bulk_extractor scan of /corp.
There are two approaches for creating the dfxml from govdocs:
  1) create one massive dfxml from all of govdocs.
  2) create dfxml for each primary directory under govdocs.

Compile on ncr.nps.edu.
Perform testing on r2.ncr.nps.edu.
Note available file r0.ncr.nps.edu /corp/quist/malware/files-4096.xml

Write small test programs for code that breaks BTree.
Known causes:
1) create empty BTree, then check for presence of an entry.
2) Reading using bulk_extractor recursive.

------------------------------------------------------------
Done:

Boost:
Use Boost extraction tool BCP to assemble required headers for tarball and
have autotools choose native Boost over assembled headers.
(bda): No, bcp tool created 1.3MB zip, without libs, so I may not pursue 
       assembled headers unless further directed.
Put back filesystem v3 compatibility for Boost v1.48 onward.
(bda): Done.

Functionality:
Added new scan parameter, sector_size, which is different from hash block size,
so that hashes can be managed on sector boundaries.

Added -x parameter to copy command to remove duplicates.
The implementation may be optimised in the future.

Renamed client request offset to query_id because it is an ID that is
not necessarily bound to an offset.

Usage now shows default values.

Locked the socket map during access so that threads can't break it.

Allow multiple targets:
Compiles to c++98, not just C++11, in order to improve compiler portability.

Added BTree input parameter option for specifying number of hashes
instead of number of hash functions k and hash size M.
Joel and Avner will provide feedback on hashdb usage.
Add new hashdb command for regenerating the Bloom filter
using different Bloom filter parameters.
Write the scan_md5 bulk_extractor plugin.
Help James with client code.
Add runtime timer information.

Improved integration with bulk_extractor.

Allows multiple targets: Linux, Windows, Mac.

Databases are portable across Linux, Windows32/Windows64, Mac.

Added hashdb API query functionality: query_sources_md5 and
query_hashdb_info are fully implemented.

------------------------------------------------------------
We will update the query interface to provide "add hash" services.  The
motivating use-case is to be able to generate whitelist hash values using
bulk_extractor.  Specifically, we will import block hashes of disk image
sectors into a hash database for multiple images, and then merging these
hashes.  We then use hash values that are common to multiple images as
whitelist hash values to be excluded from blacklist data.

Query services will be adjusted and added to to support additional interfaces.
Changes include:

The hashdb API interfaces are incorrectly prefixed with "query_".  Term
query will be renamed to hashdb to properly reflect that it is a hashdb API.

File hashdb.h is already properly named as "hashdb".

Code that dispatches queries to ZMQ are improperly named query*.hpp.  These
files will be renamed to zmq*.hpp and will have new API interfaces added to
support all hashdb access functions, not just queries.  Most significantly,
the ability to add hashes will be supported: "hashdb_add_hash_elements".

Existing code that accesses the hashdb databases is duplicated, once for
server code that services ZMQ requests, and once for query code that
bypasses ZMQ and accesses hashdb databases directly.  This will be changed
so that accesses uniformly go through ZMQ, wheter the server side is local
or remote.  This change needs to be made before more hashdb access functons
are added.

A complication with ZMQ has been managing variable-sizd records because of
strings used for repository names and filenames.  Now that Boost 1.43
has introduced the string_ref class, I will change ZMQ to use this type
for transmitting arrays of records containing string data.

All hashdb interfaces will be changed to not throw events or call
exit.  Specifically, Boost exceptions will be caught and converted to error
codes and any invocations of exit will be replaced by error codes.
Currently, error codes are used, but they only return 0 or 1.

Since the hashdb API interfaces will be functionally complete for all hashdb
actions, the hashdb_manager tool will be changed to use the hashdb API
rather than have code that replicates what the hashdb API does.

The hashdb_checker tool will be merged into the hashdb_manager tool
because these tool services are no longer distinct; the hashdb API will
support both read and write servcies.  Note that the hashdb_manager tool
already uses the hashdb API.

