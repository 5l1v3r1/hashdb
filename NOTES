------------------------------------------------------------
Here is a summary of design strategies and configurable B-Tree parameters
that impact B-Tree performance:

 * Key size.  The Key size used impacts performance the most because it
   impacts the depth of the tree.  When the key size is small, more
   child elements fit in a node, resulting in a shorter tree.

   An indexed map can be used to minimize Key size, but each indexed map
   lookup is paired with a flat-map lookup of the Key's value, so indexed
   maps cannot have better performance than direct maps.

 * Node size, default 4096.  Larger nodes hold more child nodes, shortening
   the tree, specifically # child nodes = ( node size - overhead ) / Key size.
   Larger node sizes permit shorter trees, but the extra data read is not used;
   less than 4096 bytes of
   information is needed from the node, and reading more than the
   operating system's 4096-byte block size takes time, too.  In fact,
   on a discontiguous block read, the cost of reading a second 4096-byte
   block is equivalent to the cost of reading a node in the next branch of
   the tree.

   In other words, the node size should be the same as the block size used
   by the OS, typically 4096.

   The node size may be selected by passing it in to the btree constructor.

 * Traits: Endian traits are configurable to big, little, or native endian.
   Beman has chosen big-endian traits because this is portable and readable
   and the choice makes no measurable effect on performance.

   The traits used is selected by passing the desired traits class as a
   template parameter to the desired btree type during class instantiation.

 * Preload: Preload to OS file cache.  Enabled by flag in Open call.  This
   does not load the btree cache, but btree can be changed so that it does.

 * Cache branches: enable permanent cache of all branch nodes touched.
   The btree buffer manager will never deallocate nodes that have been read.
   Enabled by flag in Open call.

 * Caching: Amount of caching is selectable based on ratio of file size.
   We will select "fastest".  We may select "least_memory" for testing
   performance.  Selected by flag in Open call.  May also be changed during
   runtime via max_cache_size.

   Unused buffers are deallocated based on an algorithm when buffers
   reach max_cache_size.

 * reserve_default: Bytes to reserve for the flat file that is created when
   using indexed sets and maps.  Not used for sets and maps that are not
   indexed.

Here are optimizing B-Tree design characteristics which are different from
the classical B+ tree:
 * New-node-on-full (lazy) rather than split on full for ordered inserts
   allow 100% packing

 * Free-at-empty (lazy) rather than rebalancing erases.

Implementation optimizations we may want to request:
 * Add function "apply(key, mapped_value)" to insert if key not present,
   or update mapped_value if present.

   We change mapped_value for keys in the hash store when we add or remove
   elements from the hash duplicates store.

What this means for hashdb:
 * May want preload option if opening as socket service well before use.
 * No other user options; btree will be hardcoded for maximum speed and will
   use lots of memory.
 * Always open with "fastest" flag to maximize caching.
 * Do not preload.
 * Use default traits.
 * Use default node size of 4096 bytes.
 * Design with minimal key+value size, which we do.
 * We may request new "apply" interface to enable more efficient performance
   when changing a mapped_value.

------------------------------------------------------------
Obscure boost::btree errors from programming errors:
It would be nice if btree had more checks during instantiation in order
to help with programming errors.  Currently, misuse results in segmentation
faults from deep in Boost.  These errors are from my mistakes:
1) Close after creating and modifying a new btree.  I failed to call delete
after new.  After next open, read crashed.
2) When opening an index file, pass index_by_key(file), not key_file.
The compiler allows this because the method prototype is available.  But it
is the wrong one.  I don't know if a check is possible for this error.

------------------------------------------------------------
Compiler warnings
 * btree code generates warnings so warnings are disabled with the -isystem
   compiler flag.  A comparison warning still shows even with warnings
   disabled.

The mingw compiler does not see "assert(0)" as terminal, so for functions
with non-void return parameters, I then immediately call "exit(1)"
to quiet the compiler warning.

------------------------------------------------------------
Tagging a version and Uploading to digitalcorpora
 * $ git tag -a v0.9.1 -m "v0.9.1
   $ git push origin --tags

 * Upload to digitalcorpora.org/downloads/hashdb
   at ncr:/var/www/digitalcorpora/downloads/hashdb

------------------------------------------------------------
ZMQ vs Boost.Asio:
ZMQ: The reply sent is routed to the client that issued the request.
     One socket is used.
Boost: Create a new socket, then
       use tcp::acceptor::accept to accept a new connection from a peer
       into the given socket.
       Then use that socket for your transaction.

ZMQ sockets work more at the port level, with paired transmit and receive
sequences, while Boost.Asio sockets are bound to specific connections.
Each connection is managed in a Thread, improving performance.
Boost.Asio is easier to use at the data protocol level because user data
is wrapped into a boost buffer for transmittal.
The buffer supports scatter/gather processing, avoiding unnecessary copies.
I use it to wrap my std::vector lookup and response data, and it works nicely.

To improve performance during transmit, I disable Nagle's algorithm
via "my_socket.set_option(tcp::no_delay(true))".

The hashdb client makes one transaction per call.
I send a count of hashes and
then a vector of hashes.  For MD5, this is uint32_t and then
std::vector<md5_t>.  The number of hashes sent depends on the block
size, the sector size, and sbuf.pagesize.  For example with a block size
of 4096, a sector size of 512, and a pagesize of 4096+512, I send a
count of two and then a vector of two hashes to scan.  For a pagesize of
16,773,632, I send a count and hashes for 16,773,632/512 = 32,761
hashes.  Since MD5 hashes are 16 bytes in size, the two examples are a
payload of 4 and a payload of 2*8=32, and a payload of 4 and a payload
of 32,761*16=524,176 bytes, respectively.

The response consists of a count of
matches and then a std::vector<std::pair<uint32_t, uint32_t>> of
matches, where each std::pair<uint32_t, uint32_t> represents the index
of a hash and the number of times the hash was sourced in the database. 
Nothing is returned for hashes that were not matched, so the returned
response vector will usually be empty.  Both the request and response
vectors are managed on the heap.

In the future, I may improve scanner performance more by having the scanner
thread hand off hashdb scan requests to a separate lookup queue,
allowing the scanner to begin processing the next sbuf
rather than waiting for the Server's response before moving on.

I should also double up write requests so that count and data are sent at once,
thereby preventing a separate packet from going over the wire.

------------------------------------------------------------
gnu screen
Start screen by "ssh -t user@path screen -d -r"

