Things to do:

------------------------------------------------------------
Functinality:

Submit for second internal review.

Post first release.

Allow multiple targets:
Make Windows target and later make Mac target.  Not just Linux target.
If libxml++ wrapper is problematic, port to libxml2.
If zeromq is problematic, port to Boost interprocess.

Add new option to not pack upon saving.  Add feedback to indicate
when packing starts and stops.

Add API to look up source repository name and filename.
This is functionally missing, and also prevents regression testing.

Change lookup API to manage lookups in sorted array groups.
Currently, embedded scanner does not use this API.
The local-mode scanner work like the client scanner with array
to allow sort option.

Update documentation so it is not wrong (2 days).

------------------------------------------------------------
Functinality, later:
Make databases portable across systems, for example 64-bit Fedora and
32-bit Windows.

May optimise the -x command that entirely removes popular hashes.

Add another map to map the repository index to the repository name.
In the future, this map may be part of the metadata.

Truncate long file paths to the right, not the left, else use
variable-length string records.

Maybe shard Bloom filter.

Encrypt traffic through zmq socket.

Write small test programs for code that breaks BTree.
Known causes:
1) create empty BTree, then check for presence of an entry.
2) Reading using bulk_extractor recursive.

Compile with another compiler, try clang.

------------------------------------------------------------
Notes:

Naming: May call chunk_size the hash block size.

Provide note to user: Don't open a hashdb RW that is opened RO for reading
or reads will break.

------------------------------------------------------------
Testing:
Create hashdb of /corp/nps/files/govdocs1/.
Create hashdb of malware/.
Work under /raid/bdallen.
Perform bulk_extractor scan of /corp.
There are two approaches for creating the dfxml from govdocs:
  1) create one massive dfxml from all of govdocs.
  2) create dfxml for each primary directory under govdocs.

Compile on ncr.nps.edu.
Perform testing on r2.ncr.nps.edu.
Note available file r0.ncr.nps.edu /corp/quist/malware/files-4096.xml

------------------------------------------------------------
Done:

Boost:
Use Boost extraction tool BCP to assemble required headers for tarball and
have autotools choose native Boost over assembled headers.
(bda): No, bcp tool created 1.3MB zip, without libs, so I may not pursue 
       assembled headers unless further directed.
Put back filesystem v3 compatibility for Boost v1.48 onward.
(bda): Done.

Functionality:
Added new scan parameter, sector_size, which is different from chunk size,
so that chunk hashes can be managed on sector boundaries.

Added -x parameter to copy command to remove duplicates.
The implementation may be optimised in the future.

Renamed client request offset to query_id because it is an ID that is
not necessarily bound to an offset.

Usage now shows default values.

Locked the socket map during access so that threads can't break it.

Allow multiple targets:
Compiles to c++98, not just C++11, in order to improve compiler portability.

Add BTree input parameter option for specifying number of hashes
instead of number of hash functions k and hash size M.
Joel and Avner will provide feedback on hashdb usage.
Add new hashdb command for regenerating the Bloom filter
using different Bloom filter parameters.
Write the scan_md5 bulk_extractor plugin.
Help James with client code.
Add runtime timer information.

Improve integration with bulk_extractor:
1) use be_config_t be_config parameter: "hashdb_path=<path>"
   and open DB from scanner.
2) use opt_scan_bulk_block_size when opening DB to validate chunk size match.
   use opt_scan_bulk_block_size in scanner to create the md5.

